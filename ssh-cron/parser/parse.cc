// Generated by Bisonc++ V4.09.01 on Thu, 15 May 2014 09:30:55 +0200

// $insert class.ih
#include "parser.ih"

// The FIRST element of SR arrays shown below uses `d_type', defining the
// state's type, and `d_lastIdx' containing the last element's index. If
// d_lastIdx contains the REQ_TOKEN bitflag (see below) then the state needs
// a token: if in this state d_token__ is _UNDETERMINED_, nextToken() will be
// called

// The LAST element of SR arrays uses `d_token' containing the last retrieved
// token to speed up the (linear) seach.  Except for the first element of SR
// arrays, the field `d_action' is used to determine what to do next. If
// positive, it represents the next state (used with SHIFT); if zero, it
// indicates `ACCEPT', if negative, -d_action represents the number of the
// rule to reduce to.

// `lookup()' tries to find d_token__ in the current SR array. If it fails, and
// there is no default reduction UNEXPECTED_TOKEN__ is thrown, which is then
// caught by the error-recovery function.

// The error-recovery function will pop elements off the stack until a state
// having bit flag ERR_ITEM is found. This state has a transition on _error_
// which is applied. In this _error_ state, while the current token is not a
// proper continuation, new tokens are obtained by nextToken(). If such a
// token is found, error recovery is successful and the token is
// handled according to the error state's SR table and parsing continues.
// During error recovery semantic actions are ignored.

// A state flagged with the DEF_RED flag will perform a default
// reduction if no other continuations are available for the current token.

// The ACCEPT STATE never shows a default reduction: when it is reached the
// parser returns ACCEPT(). During the grammar
// analysis phase a default reduction may have been defined, but it is
// removed during the state-definition phase.

// So:
//      s_x[] = 
//      {
//                  [_field_1_]         [_field_2_]
//
// First element:   {state-type,        idx of last element},
// Other elements:  {required token,    action to perform},
//                                      ( < 0: reduce, 
//                                          0: ACCEPT,
//                                        > 0: next state)
// Last element:    {set to d_token__,    action to perform}
//      }

// When the --thread-safe option is specified, all static data are defined as
// const. If --thread-safe is not provided, the state-tables are not defined
// as const, since the lookup() function below will modify them


namespace // anonymous
{
    char const author[] = "Frank B. Brokken (f.b.brokken@rug.nl)";

    enum 
    {
        STACK_EXPANSION = 5     // size to expand the state-stack with when
                                // full
    };

    enum ReservedTokens
    {
        PARSE_ACCEPT     = 0,   // `ACCEPT' TRANSITION
        _UNDETERMINED_   = -2,
        _EOF_            = -1,
        _error_          = 256
    };
    enum StateType       // modify statetype/data.cc when this enum changes
    {
        NORMAL,
        ERR_ITEM,
        REQ_TOKEN,
        ERR_REQ,    // ERR_ITEM | REQ_TOKEN
        DEF_RED,    // state having default reduction
        ERR_DEF,    // ERR_ITEM | DEF_RED
        REQ_DEF,    // REQ_TOKEN | DEF_RED
        ERR_REQ_DEF // ERR_ITEM | REQ_TOKEN | DEF_RED
    };    
    struct PI__     // Production Info
    {
        size_t d_nonTerm; // identification number of this production's
                            // non-terminal 
        size_t d_size;    // number of elements in this production 
    };

    struct SR__     // Shift Reduce info, see its description above
    {
        union
        {
            int _field_1_;      // initializer, allowing initializations 
                                // of the SR s_[] arrays
            int d_type;
            int d_token;
        };
        union
        {
            int _field_2_;

            int d_lastIdx;          // if negative, the state uses SHIFT
            int d_action;           // may be negative (reduce), 
                                    // postive (shift), or 0 (accept)
            size_t d_errorState;    // used with Error states
        };
    };

    // $insert staticdata
    
// Productions Info Records:
PI__ const s_productionInfo[] = 
{
     {0, 0}, // not used: reduction values are negative
     {271, 2}, // 1: startrule ->  startrule line
     {271, 0}, // 2: startrule ->  <empty>
     {273, 1}, // 3: nr (NR) ->  NR
     {274, 0}, // 4: opt_nr_step ->  <empty>
     {274, 2}, // 5: opt_nr_step ('/') ->  '/' nr
     {275, 1}, // 6: nr_add ->  nr
     {276, 4}, // 7: nr_range ('-') ->  nr '-' nr opt_nr_step
     {276, 1}, // 8: nr_range ->  nr_add
     {277, 3}, // 9: nr_Sequence (',') ->  nr_Sequence ',' nr_range
     {277, 1}, // 10: nr_Sequence ->  nr_range
     {278, 1}, // 11: opt_ws (WS) ->  WS
     {278, 0}, // 12: opt_ws ->  <empty>
     {279, 1}, // 13: _tokenNoWs (NR) ->  NR
     {279, 1}, // 14: _tokenNoWs (ID) ->  ID
     {279, 1}, // 15: _tokenNoWs ('*') ->  '*'
     {279, 1}, // 16: _tokenNoWs ('/') ->  '/'
     {279, 1}, // 17: _tokenNoWs (',') ->  ','
     {279, 1}, // 18: _tokenNoWs ('-') ->  '-'
     {279, 1}, // 19: _tokenNoWs (CHAR) ->  CHAR
     {279, 1}, // 20: _tokenNoWs ('=') ->  '='
     {280, 1}, // 21: _tokenAny (WS) ->  WS
     {280, 1}, // 22: _tokenAny ->  _tokenNoWs
     {281, 0}, // 23: _tokenMatched ->  <empty>
     {282, 2}, // 24: _tokenAnyMatched ->  _tokenAny _tokenMatched
     {283, 2}, // 25: token_noWs ->  _tokenNoWs _tokenMatched
     {284, 2}, // 26: tokens ->  tokens _tokenAny
     {284, 1}, // 27: tokens ->  _tokenAnyMatched
     {285, 1}, // 28: opt_tokens ->  tokens
     {285, 0}, // 29: opt_tokens ->  <empty>
     {286, 3}, // 30: _nameContents ('=') ->  opt_ws '=' opt_tokens
     {287, 1}, // 31: _nameID (ID) ->  ID
     {288, 2}, // 32: nameLine ->  _nameID _nameContents
     {289, 2}, // 33: _all ('*') ->  '*' opt_nr_step
     {290, 1}, // 34: _timeUnit ->  nr_range
     {290, 1}, // 35: _timeUnit (ID) ->  ID
     {291, 3}, // 36: _timeSequence (',') ->  _timeSequence ',' _timeUnit
     {291, 1}, // 37: _timeSequence ->  _timeUnit
     {292, 1}, // 38: time_numberedSpec ->  _all
     {292, 1}, // 39: time_numberedSpec ->  nr_Sequence
     {293, 1}, // 40: time_spec ->  _all
     {293, 1}, // 41: time_spec ->  _timeSequence
     {294, 2}, // 42: _minutes (WS) ->  time_numberedSpec WS
     {295, 2}, // 43: _hours (WS) ->  time_numberedSpec WS
     {296, 2}, // 44: _dayOfMonth (WS) ->  time_numberedSpec WS
     {297, 2}, // 45: _monthOfYear (WS) ->  time_spec WS
     {298, 2}, // 46: _dayOfWeek (WS) ->  time_spec WS
     {299, 2}, // 47: _command ->  token_noWs opt_tokens
     {300, 6}, // 48: cronLine ->  _minutes _hours _dayOfMonth _monthOfYear _dayOfWeek _command
     {301, 1}, // 49: _line_contents ->  nameLine
     {301, 1}, // 50: _line_contents ->  cronLine
     {301, 1}, // 51: _line_contents (_error_) ->  _error_
     {302, 0}, // 52: _line_preamble ->  <empty>
     {303, 2}, // 53: _opt_line_contents ->  _line_preamble _line_contents
     {303, 0}, // 54: _opt_line_contents ->  <empty>
     {272, 2}, // 55: line ('\x0a') ->  _opt_line_contents '\x0a'
     {304, 1}, // 56: startrule_$ ->  startrule
};

// State info and SR__ transitions for each state.


SR__ s_0[] =
{
    { { DEF_RED}, {  2} },             
    { {     271}, {  1} }, // startrule
    { {       0}, { -2} },             
};

SR__ s_1[] =
{
    { { REQ_DEF}, {            6} },                      
    { {     272}, {            2} }, // line              
    { {     303}, {            3} }, // _opt_line_contents
    { {     302}, {            4} }, // _line_preamble    
    { {   _EOF_}, { PARSE_ACCEPT} },                      
    { {      10}, {          -54} }, // '\x0a'            
    { {       0}, {          -52} },                      
};

SR__ s_2[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -1} }, 
};

SR__ s_3[] =
{
    { { REQ_TOKEN}, { 2} },          
    { {        10}, { 5} }, // '\x0a'
    { {         0}, { 0} },          
};

SR__ s_4[] =
{
    { { ERR_REQ}, { 16} },                     
    { {     301}, {  6} }, // _line_contents   
    { {     288}, {  7} }, // nameLine         
    { {     300}, {  8} }, // cronLine         
    { { _error_}, {  9} }, // _error_          
    { {     287}, { 10} }, // _nameID          
    { {     294}, { 11} }, // _minutes         
    { {     259}, { 12} }, // ID               
    { {     292}, { 13} }, // time_numberedSpec
    { {     289}, { 14} }, // _all             
    { {     277}, { 15} }, // nr_Sequence      
    { {      42}, { 16} }, // '*'              
    { {     276}, { 17} }, // nr_range         
    { {     273}, { 18} }, // nr               
    { {     275}, { 19} }, // nr_add           
    { {     258}, { 20} }, // NR               
    { {       0}, {  0} },                     
};

SR__ s_5[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -55} }, 
};

SR__ s_6[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -53} }, 
};

SR__ s_7[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -49} }, 
};

SR__ s_8[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -50} }, 
};

SR__ s_9[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -51} }, 
};

SR__ s_10[] =
{
    { { REQ_DEF}, {   4} },                 
    { {     286}, {  21} }, // _nameContents
    { {     278}, {  22} }, // opt_ws       
    { {     257}, {  23} }, // WS           
    { {       0}, { -12} },                 
};

SR__ s_11[] =
{
    { { REQ_TOKEN}, { 10} },                     
    { {       295}, { 24} }, // _hours           
    { {       292}, { 25} }, // time_numberedSpec
    { {       289}, { 14} }, // _all             
    { {       277}, { 15} }, // nr_Sequence      
    { {        42}, { 16} }, // '*'              
    { {       276}, { 17} }, // nr_range         
    { {       273}, { 18} }, // nr               
    { {       275}, { 19} }, // nr_add           
    { {       258}, { 20} }, // NR               
    { {         0}, {  0} },                     
};

SR__ s_12[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -31} }, 
};

SR__ s_13[] =
{
    { { REQ_TOKEN}, {  2} },      
    { {       257}, { 26} }, // WS
    { {         0}, {  0} },      
};

SR__ s_14[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -38} }, 
};

SR__ s_15[] =
{
    { { REQ_DEF}, {   2} },       
    { {      44}, {  27} }, // ','
    { {       0}, { -39} },       
};

SR__ s_16[] =
{
    { { REQ_DEF}, {  3} },               
    { {     274}, { 28} }, // opt_nr_step
    { {      47}, { 29} }, // '/'        
    { {       0}, { -4} },               
};

SR__ s_17[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -10} }, 
};

SR__ s_18[] =
{
    { { REQ_DEF}, {  2} },       
    { {      45}, { 30} }, // '-'
    { {       0}, { -6} },       
};

SR__ s_19[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -8} }, 
};

SR__ s_20[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -3} }, 
};

SR__ s_21[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -32} }, 
};

SR__ s_22[] =
{
    { { REQ_TOKEN}, {  2} },       
    { {        61}, { 31} }, // '='
    { {         0}, {  0} },       
};

SR__ s_23[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -11} }, 
};

SR__ s_24[] =
{
    { { REQ_TOKEN}, { 10} },                     
    { {       296}, { 32} }, // _dayOfMonth      
    { {       292}, { 33} }, // time_numberedSpec
    { {       289}, { 14} }, // _all             
    { {       277}, { 15} }, // nr_Sequence      
    { {        42}, { 16} }, // '*'              
    { {       276}, { 17} }, // nr_range         
    { {       273}, { 18} }, // nr               
    { {       275}, { 19} }, // nr_add           
    { {       258}, { 20} }, // NR               
    { {         0}, {  0} },                     
};

SR__ s_25[] =
{
    { { REQ_TOKEN}, {  2} },      
    { {       257}, { 34} }, // WS
    { {         0}, {  0} },      
};

SR__ s_26[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -42} }, 
};

SR__ s_27[] =
{
    { { REQ_TOKEN}, {  5} },            
    { {       276}, { 35} }, // nr_range
    { {       273}, { 18} }, // nr      
    { {       275}, { 19} }, // nr_add  
    { {       258}, { 20} }, // NR      
    { {         0}, {  0} },            
};

SR__ s_28[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -33} }, 
};

SR__ s_29[] =
{
    { { REQ_TOKEN}, {  3} },      
    { {       273}, { 36} }, // nr
    { {       258}, { 20} }, // NR
    { {         0}, {  0} },      
};

SR__ s_30[] =
{
    { { REQ_TOKEN}, {  3} },      
    { {       273}, { 37} }, // nr
    { {       258}, { 20} }, // NR
    { {         0}, {  0} },      
};

SR__ s_31[] =
{
    { { REQ_DEF}, {  15} },                    
    { {     285}, {  38} }, // opt_tokens      
    { {     284}, {  39} }, // tokens          
    { {     282}, {  40} }, // _tokenAnyMatched
    { {     280}, {  41} }, // _tokenAny       
    { {     257}, {  42} }, // WS              
    { {     279}, {  43} }, // _tokenNoWs      
    { {     258}, {  44} }, // NR              
    { {     259}, {  45} }, // ID              
    { {      42}, {  46} }, // '*'             
    { {      47}, {  47} }, // '/'             
    { {      44}, {  48} }, // ','             
    { {      45}, {  49} }, // '-'             
    { {     260}, {  50} }, // CHAR            
    { {      61}, {  51} }, // '='             
    { {       0}, { -29} },                    
};

SR__ s_32[] =
{
    { { REQ_TOKEN}, { 12} },                 
    { {       297}, { 52} }, // _monthOfYear 
    { {       293}, { 53} }, // time_spec    
    { {       289}, { 54} }, // _all         
    { {       291}, { 55} }, // _timeSequence
    { {        42}, { 16} }, // '*'          
    { {       290}, { 56} }, // _timeUnit    
    { {       276}, { 57} }, // nr_range     
    { {       259}, { 58} }, // ID           
    { {       273}, { 18} }, // nr           
    { {       275}, { 19} }, // nr_add       
    { {       258}, { 20} }, // NR           
    { {         0}, {  0} },                 
};

SR__ s_33[] =
{
    { { REQ_TOKEN}, {  2} },      
    { {       257}, { 59} }, // WS
    { {         0}, {  0} },      
};

SR__ s_34[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -43} }, 
};

SR__ s_35[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -9} }, 
};

SR__ s_36[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -5} }, 
};

SR__ s_37[] =
{
    { { REQ_DEF}, {  3} },               
    { {     274}, { 60} }, // opt_nr_step
    { {      47}, { 29} }, // '/'        
    { {       0}, { -4} },               
};

SR__ s_38[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -30} }, 
};

SR__ s_39[] =
{
    { { REQ_DEF}, {  12} },              
    { {     280}, {  61} }, // _tokenAny 
    { {     257}, {  42} }, // WS        
    { {     279}, {  43} }, // _tokenNoWs
    { {     258}, {  44} }, // NR        
    { {     259}, {  45} }, // ID        
    { {      42}, {  46} }, // '*'       
    { {      47}, {  47} }, // '/'       
    { {      44}, {  48} }, // ','       
    { {      45}, {  49} }, // '-'       
    { {     260}, {  50} }, // CHAR      
    { {      61}, {  51} }, // '='       
    { {       0}, { -28} },              
};

SR__ s_40[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -27} }, 
};

SR__ s_41[] =
{
    { { DEF_RED}, {   2} },                 
    { {     281}, {  62} }, // _tokenMatched
    { {       0}, { -23} },                 
};

SR__ s_42[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -21} }, 
};

SR__ s_43[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -22} }, 
};

SR__ s_44[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -13} }, 
};

SR__ s_45[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -14} }, 
};

SR__ s_46[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -15} }, 
};

SR__ s_47[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -16} }, 
};

SR__ s_48[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -17} }, 
};

SR__ s_49[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -18} }, 
};

SR__ s_50[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -19} }, 
};

SR__ s_51[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -20} }, 
};

SR__ s_52[] =
{
    { { REQ_TOKEN}, { 12} },                 
    { {       298}, { 63} }, // _dayOfWeek   
    { {       293}, { 64} }, // time_spec    
    { {       289}, { 54} }, // _all         
    { {       291}, { 55} }, // _timeSequence
    { {        42}, { 16} }, // '*'          
    { {       290}, { 56} }, // _timeUnit    
    { {       276}, { 57} }, // nr_range     
    { {       259}, { 58} }, // ID           
    { {       273}, { 18} }, // nr           
    { {       275}, { 19} }, // nr_add       
    { {       258}, { 20} }, // NR           
    { {         0}, {  0} },                 
};

SR__ s_53[] =
{
    { { REQ_TOKEN}, {  2} },      
    { {       257}, { 65} }, // WS
    { {         0}, {  0} },      
};

SR__ s_54[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -40} }, 
};

SR__ s_55[] =
{
    { { REQ_DEF}, {   2} },       
    { {      44}, {  66} }, // ','
    { {       0}, { -41} },       
};

SR__ s_56[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -37} }, 
};

SR__ s_57[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -34} }, 
};

SR__ s_58[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -35} }, 
};

SR__ s_59[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -44} }, 
};

SR__ s_60[] =
{
    { { DEF_RED}, {  1} }, 
    { {       0}, { -7} }, 
};

SR__ s_61[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -26} }, 
};

SR__ s_62[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -24} }, 
};

SR__ s_63[] =
{
    { { REQ_TOKEN}, { 12} },              
    { {       299}, { 67} }, // _command  
    { {       283}, { 68} }, // token_noWs
    { {       279}, { 69} }, // _tokenNoWs
    { {       258}, { 44} }, // NR        
    { {       259}, { 45} }, // ID        
    { {        42}, { 46} }, // '*'       
    { {        47}, { 47} }, // '/'       
    { {        44}, { 48} }, // ','       
    { {        45}, { 49} }, // '-'       
    { {       260}, { 50} }, // CHAR      
    { {        61}, { 51} }, // '='       
    { {         0}, {  0} },              
};

SR__ s_64[] =
{
    { { REQ_TOKEN}, {  2} },      
    { {       257}, { 70} }, // WS
    { {         0}, {  0} },      
};

SR__ s_65[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -45} }, 
};

SR__ s_66[] =
{
    { { REQ_TOKEN}, {  7} },             
    { {       290}, { 71} }, // _timeUnit
    { {       276}, { 57} }, // nr_range 
    { {       259}, { 58} }, // ID       
    { {       273}, { 18} }, // nr       
    { {       275}, { 19} }, // nr_add   
    { {       258}, { 20} }, // NR       
    { {         0}, {  0} },             
};

SR__ s_67[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -48} }, 
};

SR__ s_68[] =
{
    { { REQ_DEF}, {  15} },                    
    { {     285}, {  72} }, // opt_tokens      
    { {     284}, {  39} }, // tokens          
    { {     282}, {  40} }, // _tokenAnyMatched
    { {     280}, {  41} }, // _tokenAny       
    { {     257}, {  42} }, // WS              
    { {     279}, {  43} }, // _tokenNoWs      
    { {     258}, {  44} }, // NR              
    { {     259}, {  45} }, // ID              
    { {      42}, {  46} }, // '*'             
    { {      47}, {  47} }, // '/'             
    { {      44}, {  48} }, // ','             
    { {      45}, {  49} }, // '-'             
    { {     260}, {  50} }, // CHAR            
    { {      61}, {  51} }, // '='             
    { {       0}, { -29} },                    
};

SR__ s_69[] =
{
    { { DEF_RED}, {   2} },                 
    { {     281}, {  73} }, // _tokenMatched
    { {       0}, { -23} },                 
};

SR__ s_70[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -46} }, 
};

SR__ s_71[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -36} }, 
};

SR__ s_72[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -47} }, 
};

SR__ s_73[] =
{
    { { DEF_RED}, {   1} }, 
    { {       0}, { -25} }, 
};


// State array:
SR__ *s_state[] =
{
  s_0,  s_1,  s_2,  s_3,  s_4,  s_5,  s_6,  s_7,  s_8,  s_9,
  s_10,  s_11,  s_12,  s_13,  s_14,  s_15,  s_16,  s_17,  s_18,  s_19,
  s_20,  s_21,  s_22,  s_23,  s_24,  s_25,  s_26,  s_27,  s_28,  s_29,
  s_30,  s_31,  s_32,  s_33,  s_34,  s_35,  s_36,  s_37,  s_38,  s_39,
  s_40,  s_41,  s_42,  s_43,  s_44,  s_45,  s_46,  s_47,  s_48,  s_49,
  s_50,  s_51,  s_52,  s_53,  s_54,  s_55,  s_56,  s_57,  s_58,  s_59,
  s_60,  s_61,  s_62,  s_63,  s_64,  s_65,  s_66,  s_67,  s_68,  s_69,
  s_70,  s_71,  s_72,  s_73,
};

} // anonymous namespace ends



// If the parsing function call uses arguments, then provide an overloaded
// function.  The code below doesn't rely on parameters, so no arguments are
// required.  Furthermore, parse uses a function try block to allow us to do
// ACCEPT and ABORT from anywhere, even from within members called by actions,
// simply throwing the appropriate exceptions.

ParserBase::ParserBase()
:
    d_stackIdx__(-1),
    // $insert debuginit
    d_debug__(false),
    d_nErrors__(0),
    // $insert requiredtokens
    d_requiredTokens__(0),
    d_acceptedTokens__(d_requiredTokens__),
    d_token__(_UNDETERMINED_),
    d_nextToken__(_UNDETERMINED_)
{}


void Parser::print__()
{
// $insert print
}

void ParserBase::clearin()
{
    d_token__ = d_nextToken__ = _UNDETERMINED_;
}

void ParserBase::push__(size_t state)
{
    if (static_cast<size_t>(d_stackIdx__ + 1) == d_stateStack__.size())
    {
        size_t newSize = d_stackIdx__ + STACK_EXPANSION;
        d_stateStack__.resize(newSize);
        d_valueStack__.resize(newSize);
    }
    ++d_stackIdx__;
    d_stateStack__[d_stackIdx__] = d_state__ = state;
    *(d_vsp__ = &d_valueStack__[d_stackIdx__]) = d_val__;
}

void ParserBase::popToken__()
{
    d_token__ = d_nextToken__;

    d_val__ = d_nextVal__;
    d_nextVal__ = STYPE__();

    d_nextToken__ = _UNDETERMINED_;
}
     
void ParserBase::pushToken__(int token)
{
    d_nextToken__ = d_token__;
    d_nextVal__ = d_val__;
    d_token__ = token;
}
     
void ParserBase::pop__(size_t count)
{
    if (d_stackIdx__ < static_cast<int>(count))
    {
        ABORT();
    }

    d_stackIdx__ -= count;
    d_state__ = d_stateStack__[d_stackIdx__];
    d_vsp__ = &d_valueStack__[d_stackIdx__];
}

inline size_t ParserBase::top__() const
{
    return d_stateStack__[d_stackIdx__];
}

void Parser::executeAction(int production)
try
{
    if (d_token__ != _UNDETERMINED_)
        pushToken__(d_token__);     // save an already available token

                                    // save default non-nested block $$
    if (int size = s_productionInfo[production].d_size)
        d_val__ = d_vsp__[1 - size];

    switch (production)
    {
        // $insert actioncases
        
        case 3:
#line 3 "inc/nr"
        {
         d_val__.get<Tag__::INT>() = stol(d_scanner.matched());
         }
        break;

        case 4:
#line 10 "inc/nr"
        {
         d_val__.get<Tag__::INT>() = 1;
         }
        break;

        case 5:
#line 15 "inc/nr"
        {
         d_val__.get<Tag__::INT>() = d_vsp__[0].data<Tag__::INT>();
         }
        break;

        case 6:
#line 22 "inc/nr"
        {
         d_cronData.addNr(d_vsp__[0].data<Tag__::INT>());
         }
        break;

        case 7:
#line 30 "inc/nr"
        {
         d_cronData.addRange(d_vsp__[-3].data<Tag__::INT>(), d_vsp__[-1].data<Tag__::INT>(), d_vsp__[0].data<Tag__::INT>());
         }
        break;

        case 23:
#line 26 "inc/token"
        {
         d_val__.get<Tag__::STRING>() = d_scanner.matched();
         }
        break;

        case 24:
#line 35 "inc/token"
        {
         d_val__.get<Tag__::STRING>() = d_vsp__[0].data<Tag__::STRING>();
         }
        break;

        case 25:
#line 43 "inc/token"
        {
         d_val__.get<Tag__::STRING>() =d_vsp__[0].data<Tag__::STRING>();
         }
        break;

        case 26:
#line 50 "inc/token"
        {
         d_val__.get<Tag__::STRING>() += d_scanner.matched();
         }
        break;

        case 27:
#line 55 "inc/token"
        {
         d_val__.get<Tag__::STRING>() = d_val__.get<Tag__::STRING>();
         }
        break;

        case 29:
#line 63 "inc/token"
        {
         d_val__.get<Tag__::STRING>() = string();
         }
        break;

        case 30:
#line 8 "inc/nameline"
        {
         d_val__.get<Tag__::STRING>() = d_vsp__[0].data<Tag__::STRING>();
         }
        break;

        case 31:
#line 15 "inc/nameline"
        {
         d_val__.get<Tag__::STRING>() = d_scanner.matched();
         }
        break;

        case 32:
#line 22 "inc/nameline"
        {
         d_cronData.setEnvVar(d_vsp__[-1].data<Tag__::STRING>(), d_vsp__[0].data<Tag__::STRING>());
         }
        break;

        case 33:
#line 3 "inc/time"
        {
         d_cronData.setAll(d_vsp__[0].data<Tag__::INT>());
         }
        break;

        case 35:
#line 12 "inc/time"
        {
         d_cronData.addName(d_scanner.matched());
         }
        break;

        case 42:
#line 4 "inc/cronline"
        {
         d_cronData.setMinutes();
         }
        break;

        case 43:
#line 12 "inc/cronline"
        {
         d_cronData.setHours();
         }
        break;

        case 44:
#line 20 "inc/cronline"
        {
         d_cronData.setDayOfMonth();
         }
        break;

        case 45:
#line 28 "inc/cronline"
        {
         d_cronData.setMonthOfYear();
         }
        break;

        case 46:
#line 36 "inc/cronline"
        {
         d_cronData.setDayOfWeek();
         }
        break;

        case 47:
#line 44 "inc/cronline"
        {
         d_cronData.setCommand(d_vsp__[-1].data<Tag__::STRING>() + d_vsp__[0].data<Tag__::STRING>());
         }
        break;

        case 48:
#line 51 "inc/cronline"
        {
         d_cronData.process();
         }
        break;

        case 52:
#line 10 "inc/line"
        {
         d_cronData.reset(d_scanner.lineNr());
         }
        break;

    }
}
catch (std::exception const &exc)
{
    exceptionHandler__(exc);
}

inline void ParserBase::reduce__(PI__ const &pi)
{
    d_token__ = pi.d_nonTerm;
    pop__(pi.d_size);

}

// If d_token__ is _UNDETERMINED_ then if d_nextToken__ is _UNDETERMINED_ another
// token is obtained from lex(). Then d_nextToken__ is assigned to d_token__.
void Parser::nextToken()
{
    if (d_token__ != _UNDETERMINED_)        // no need for a token: got one
        return;                             // already

    if (d_nextToken__ != _UNDETERMINED_)
    {
        popToken__();                       // consume pending token
    }
    else
    {
        ++d_acceptedTokens__;               // accept another token (see
                                            // errorRecover())
        d_token__ = lex();
        if (d_token__ <= 0)
            d_token__ = _EOF_;
    }
    print();
}

// if the final transition is negative, then we should reduce by the rule
// given by its positive value. Note that the `recovery' parameter is only
// used with the --debug option
int Parser::lookup(bool recovery)
{
// $insert threading
    SR__ *sr = s_state[d_state__];          // get the appropriate state-table
    int lastIdx = sr->d_lastIdx;            // sentinel-index in the SR__ array
    
    SR__ *lastElementPtr = sr + lastIdx;
    lastElementPtr->d_token = d_token__;    // set search-token
    
    SR__ *elementPtr = sr + 1;              // start the search at s_xx[1]
    while (elementPtr->d_token != d_token__)
        ++elementPtr;
    

    if (elementPtr == lastElementPtr)   // reached the last element
    {
        if (elementPtr->d_action < 0)   // default reduction
        {
            return elementPtr->d_action;                
        }

        // No default reduction, so token not found, so error.
        throw UNEXPECTED_TOKEN__;
    }

    // not at the last element: inspect the nature of the action
    // (< 0: reduce, 0: ACCEPT, > 0: shift)

    int action = elementPtr->d_action;


    return action;
}

    // When an error has occurred, pop elements off the stack until the top
    // state has an error-item. If none is found, the default recovery
    // mode (which is to abort) is activated. 
    //
    // If EOF is encountered without being appropriate for the current state,
    // then the error recovery will fall back to the default recovery mode.
    // (i.e., parsing terminates)
void Parser::errorRecovery()
try
{
    if (d_acceptedTokens__ >= d_requiredTokens__)// only generate an error-
    {                                           // message if enough tokens 
        ++d_nErrors__;                          // were accepted. Otherwise
        error("Syntax error");                  // simply skip input

    }


    // get the error state
    while (not (s_state[top__()][0].d_type & ERR_ITEM))
    {
        pop__();
    }

    // In the error state, lookup a token allowing us to proceed.
    // Continuation may be possible following multiple reductions,
    // but eventuall a shift will be used, requiring the retrieval of
    // a terminal token. If a retrieved token doesn't match, the catch below 
    // will ensure the next token is requested in the while(true) block
    // implemented below:

    int lastToken = d_token__;                  // give the unexpected token a
                                                // chance to be processed
                                                // again.

    pushToken__(_error_);                       // specify _error_ as next token
    push__(lookup(true));                       // push the error state

    d_token__ = lastToken;                      // reactivate the unexpected
                                                // token (we're now in an
                                                // ERROR state).

    bool gotToken = true;                       // the next token is a terminal

    while (true)
    {
        try
        {
            if (s_state[d_state__]->d_type & REQ_TOKEN)
            {
                gotToken = d_token__ == _UNDETERMINED_;
                nextToken();                    // obtain next token
            }
            
            int action = lookup(true);

            if (action > 0)                 // push a new state
            {
                push__(action);
                popToken__();

                if (gotToken)
                {

                    d_acceptedTokens__ = 0;
                    return;
                }
            }
            else if (action < 0)
            {
                // no actions executed on recovery but save an already 
                // available token:
                if (d_token__ != _UNDETERMINED_)
                    pushToken__(d_token__);
 
                                            // next token is the rule's LHS
                reduce__(s_productionInfo[-action]); 
            }
            else
                ABORT();                    // abort when accepting during
                                            // error recovery
        }
        catch (...)
        {
            if (d_token__ == _EOF_)
                ABORT();                    // saw inappropriate _EOF_
                      
            popToken__();                   // failing token now skipped
        }
    }
}
catch (ErrorRecovery__)       // This is: DEFAULT_RECOVERY_MODE
{
    ABORT();
}

    // The parsing algorithm:
    // Initially, state 0 is pushed on the stack, and d_token__ as well as
    // d_nextToken__ are initialized to _UNDETERMINED_. 
    //
    // Then, in an eternal loop:
    //
    //  1. If a state does not have REQ_TOKEN no token is assigned to
    //     d_token__. If the state has REQ_TOKEN, nextToken() is called to
    //      determine d_nextToken__ and d_token__ is set to
    //     d_nextToken__. nextToken() will not call lex() unless d_nextToken__ is 
    //     _UNDETERMINED_. 
    //
    //  2. lookup() is called: 
    //     d_token__ is stored in the final element's d_token field of the
    //     state's SR_ array. 
    //
    //  3. The current token is looked up in the state's SR_ array
    //
    //  4. Depending on the result of the lookup() function the next state is
    //     shifted on the parser's stack, a reduction by some rule is applied,
    //     or the parsing function returns ACCEPT(). When a reduction is
    //     called for, any action that may have been defined for that
    //     reduction is executed.
    //
    //  5. An error occurs if d_token__ is not found, and the state has no
    //     default reduction. Error handling was described at the top of this
    //     file.

int Parser::parse()
try 
{
    push__(0);                              // initial state
    clearin();                              // clear the tokens.

    while (true)
    {
        try
        {
            if (s_state[d_state__]->d_type & REQ_TOKEN)
                nextToken();                // obtain next token


            int action = lookup(false);     // lookup d_token__ in d_state__

            if (action > 0)                 // SHIFT: push a new state
            {
                push__(action);
                popToken__();               // token processed
            }
            else if (action < 0)            // REDUCE: execute and pop.
            {
                executeAction(-action);
                                            // next token is the rule's LHS
                reduce__(s_productionInfo[-action]); 
            }
            else 
                ACCEPT();
        }
        catch (ErrorRecovery__)
        {
            errorRecovery();
        }
    }
}
catch (Return__ retValue)
{
    return retValue;
}



